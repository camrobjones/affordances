---
title: "Glenberg & Robertson (2000) NLM Baseline Analysis"
author: "Cameron Jones"
date: "27/09/2021"
output:
  html_document: 
    toc: yes
    toc_float: yes
    theme: flatly
    highlight: kate
    code_folding: hide
    number_sections: yes
  # md_document:
  #   variant: markdown_github
---

# Setup

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Load packages
suppressMessages(library(tidyverse))
suppressMessages(library(lmerTest))

```


Summary of the data:

```{r}
# Load and peek data
stimuli <- read.csv("../data/clean/stimuli_analysed.csv")

# Code condition as factor
stimuli$condition <- recode(stimuli$condition,
                            afforded = "Afforded",
                            nonafforded = "Non-Afforded",
                            related = "Related")

stimuli$condition <- factor(stimuli$condition, levels=c("Related", "Afforded", "Non-Afforded"))

# Analyse e1 and e2 separately
e1 <- stimuli %>% filter(experiment == 1)
e2 <- stimuli %>% filter(experiment == 2)

summary(stimuli)
```


# Masked Surprisal of Distinguishing Words

The first measure is the masked probability of the distinguishing word in the critical sentence.

In item 13, for example, we find the surprisal for each distinguishing word {leaves, water, clothes} in the sentence:

> Marissa forgot to bring her pillow on her camping trip. As a substitute for her pillow, she filled up an old sweater with [MASK].

I've run all of the examples through BERT (large, cased) and RoBERTA (large).

Predictions from both models show a clear gap in surprisal between Related and Afforded/Non-Afforded. BERT shows a second clear distinction between Afforded/Non-Afforded. This is less clear for RoBERTa.

```{r}

e1 %>%
  ggplot(aes(x = condition, y = bert_mask_all_mean, color=condition)) +
  geom_point(position=position_jitter(width=0.1), alpha=0.3) + 
  stat_summary(fun.data="mean_cl_boot", geom="point", size=3) + 
  stat_summary(fun.data="mean_cl_boot", geom="errorbar", width=0.2) + 
  geom_violin(alpha=0) +
  theme_minimal() + 
  theme(
    legend.position = "none"
  ) +
  scale_color_manual("Condition",
     values = c("#1eb809", "#2654d4", "#cc0502")) + 
  labs(
    y = "Masked Distinguishing Word surprisal (BERT)",
    x = "Condition"
  )

```

```{r}


e1 %>%
  ggplot(aes(x = condition, y = roberta_mask_all_mean, color=condition)) +
  geom_point(position=position_jitter(width=0.1), alpha=0.3) + 
  stat_summary(fun.data="mean_cl_boot", geom="point", size=3) + 
  stat_summary(fun.data="mean_cl_boot", geom="errorbar", width=0.2) + 
  geom_violin(alpha=0) +
  theme_minimal() + 
  theme(
    legend.position = "none"
  ) +
  scale_color_manual("Condition",
     values = c("#1eb809", "#2654d4", "#cc0502")) + 
  labs(
    y = "Masked Distinguishing Word surprisal (RoBERTa)",
    x = "Condition"
  )

```


## Models

To compare surprisal between conditions I created two different models: one to compare Afforded to Related, and one to compare Non-Afforded to Afforded. 

### Related vs Afforded

In both models I added a random intercept by item. I wanted to add a random slope (to control for the fact that there might variable influence of the manipulation on surprisal across items) but there are too few data points.

The model summary (using `lmerTest` to get degrees of freedom) shows positive effect which approaches significance. An LRT finds a marginally significant improvement in fit for adding condition info.

```{r}

# Comparison 1: Afforded to related
e1.aff.rel <- e1 %>% filter(condition %in% c("Afforded", "Related"))

m.aff.rel.bert.base <- lmer("bert_mask_all_mean ~ 1 + dw_freq_zipf + 
                            (1 | item)",
                            data=e1.aff.rel,
                            REML = F)
m.aff.rel.bert.full <- lmer("bert_mask_all_mean ~ condition + dw_freq_zipf + 
                            (1 | item)",
                            data=e1.aff.rel,
                            REML = F)

summary(m.aff.rel.bert.full)

a.aff.rel.bert <- anova(m.aff.rel.bert.base, m.aff.rel.bert.full)
a.aff.rel.bert

```

RoBERTa shows a much stronger effect of Aff/N-Aff

```{r}

# RoBERTa

m.aff.rel.roberta.base <- lmer("roberta_mask_all_mean ~ 1 + dw_freq_zipf + 
                               (1 | item)",
                            data=e1.aff.rel,
                            REML = F)
m.aff.rel.roberta.full <- lmer("roberta_mask_all_mean ~ condition + dw_freq_zipf +
                               (1 | item)",
                            data=e1.aff.rel,
                            REML = F)

summary(m.aff.rel.roberta.full)

a.aff.rel.roberta <- anova(m.aff.rel.roberta.base, m.aff.rel.roberta.full)
a.aff.rel.roberta

```

### Afforded vs Non-Afforded

The lmerTest summary shows no significant effect on BERT surprisal for the Afforded/Non-Afforded distinction. An LRT is also non-significant.

```{r}

# Comparison 2: Afforded to Non-Afforded
e1.aff.naff <- e1 %>% filter(condition %in% c("Afforded", "Non-Afforded"))

m.aff.naff.bert.base <- lmer("bert_mask_all_mean ~ 1 + dw_freq_zipf + 
                             (1 | item)",
                            data=e1.aff.naff,
                            REML = F)
m.aff.naff.bert.full <- lmer("bert_mask_all_mean ~ condition + dw_freq_zipf + 
                             (1 | item)",
                            data=e1.aff.naff,
                            REML = F)

summary(m.aff.naff.bert.full)

a.aff.naff.bert <- anova(m.aff.naff.bert.base, m.aff.naff.bert.full)
a.aff.naff.bert

```

Nor for RoBERTa

```{r}

# RoBERTa

m.aff.naff.roberta.base <- lmer("roberta_mask_all_mean ~ 1 + dw_freq_zipf + (1 | item)",
                            data=e1.aff.naff,
                            REML = F)
m.aff.naff.roberta.full <- lmer("roberta_mask_all_mean ~ condition + dw_freq_zipf +
                                (1 | item)",
                            data=e1.aff.naff,
                            REML = F)

summary(m.aff.naff.roberta.full)

a.aff.naff.roberta <- anova(m.aff.naff.roberta.base, m.aff.naff.roberta.full)
a.aff.naff.roberta

```

Overall the results suggest that models are more sensitive to the Related/Afforded distinction (lower surprisal for Related); but not as sensitive to the affordances of non-related concepts.

# Next Sentence Prediction

The next method I tried was to get BERT to predict whether the critical sentence followed from the setting sentence. BERT produces two activation values (one for `not continuation`, one for `continuation`). From what I've read, BERT's prediction is taken to be negative if the second value is higher than the first (and vice versa).

In order to elicit probabilities from these activation values, I just used softmax (which I don't think works very well with so few values, often the values are e.g. (6, -6)). In general the probabilities are all very high and don't show much variation.

If anything Non-Afforded continuations show a slightly higher probability than Afforded and Related continuations.

```{r}


e1 %>%
  ggplot(aes(x = condition, y = bert_nsp, color=condition)) +
  geom_point(position=position_jitter(width=0.1), alpha=0.3) + 
  stat_summary(fun.data="mean_cl_boot", geom="point", size=3) + 
  stat_summary(fun.data="mean_cl_boot", geom="errorbar", width=0.2) + 
  geom_violin(alpha=0) +
  theme_minimal() + 
  theme(
    legend.position = "none"
  ) +
  scale_color_manual("Condition",
     values = c("#1eb809", "#2654d4", "#cc0502")) + 
  labs(
    y = "BERT Next Sentence Probability",
    x = "Condition"
  )


```

Models show no difference of condition for either comparison

```{r}

m.aff.rel.bert.nsp.base <- lmer("bert_nsp ~ 1 + dw_freq_zipf + (1 | item)",
                            data=e1.aff.rel,
                            REML = F)
m.aff.rel.bert.nsp.full <- lmer("bert_nsp ~ condition + dw_freq_zipf + (1 | item)",
                            data=e1.aff.rel,
                            REML = F)

summary(m.aff.rel.bert.nsp.full)

a.aff.rel.bert.nsp <- anova(m.aff.rel.bert.nsp.base, m.aff.rel.bert.nsp.full)
a.aff.rel.bert.nsp

```

```{r}

m.aff.naff.bert.nsp.base <- lmer("bert_nsp ~ 1 + dw_freq_zipf + (1 | item)",
                            data=e1.aff.naff,
                            REML = F)
m.aff.naff.bert.nsp.full <- lmer("bert_nsp ~ condition + dw_freq_zipf + (1 | item)",
                            data=e1.aff.naff,
                            REML = F)

summary(m.aff.naff.bert.nsp.full)

a.aff.naff.bert.nsp <- anova(m.aff.naff.bert.nsp.base, m.aff.naff.bert.nsp.full)
a.aff.naff.bert.nsp

```

Overall I think this metric just isn't sensitive enough to get at the relatively small manipulation we are interested in. The lack of effect for Related-Afforded means it doesn't seem appropriate to use this metric to test for an effect of Afforded/Non-Afforded.

# Embeddings

The last method, closest to the controls in the original paper, is to find the distance between the embeddings of:

a) The central and distinguishing words in a sentence
b) The setting and critical sentences

The stimuli did not contain information about the central concept, we used the example in the paper to re-create our best guess for what the central concept is.

For example, in Item 13, we use "pillow", and find the cosine between the contextualised embedding for "pillow" and "leaves".

> Marissa forgot to bring her pillow on her camping trip. As a substitute for her pillow, she filled up an old sweater with leaves.

Where the central or distinguishing phrase is multi-token, we take the mean of the embedding for all tokens. To find the embedding for the sentences, we take the mean of all tokens in the sentence (following this [tutorial](https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/#3-extracting-embeddings), thanks Sean for sending!). We could also try using the [CLS] token).

For all embeddings, I have used the second-to-last layer of BERT. It seems to perform [comparably](https://jalammar.github.io/illustrated-bert/#bert-for-feature-extraction) with more complex strategies.

In all cases, I've taken the cosine distance between the two resulting vectors.


## Central-Distinguishing

For the central-distinguishing embedding, we see a similar pattern to the mask results above: the distance for related continuations is lower than for Afforded and Non-Afforded continuations, which are comparable.

```{r}

e1 %>%
  ggplot(aes(x = condition, y = cd_cosine_bert_ln2, color=condition)) +
  geom_point(position=position_jitter(width=0.1), alpha=0.3) + 
  stat_summary(fun.data="mean_cl_boot", geom="point", size=3) + 
  stat_summary(fun.data="mean_cl_boot", geom="errorbar", width=0.2) + 
  geom_violin(alpha=0) +
  theme_minimal() + 
  theme(
    legend.position = "none"
  ) +
  scale_color_manual("Condition",
     values = c("#1eb809", "#2654d4", "#cc0502")) + 
  labs(
    y = "Central-Distinguishing Cosine (BERT)",
    x = "Condition"
  )

```

### Related vs Afforded

The model shows a significant positive effect of Afforded vs Related on cosine distance.

```{r}

# Comparison 1: Afforded to related
m.aff.rel.cd_cosine_bert_ln2.base <- lmer("cd_cosine_bert_ln2 ~ 1 + dw_freq_zipf + 
                                          (1 | item)",
                            data=e1.aff.rel,
                            REML = F)
m.aff.rel.cd_cosine_bert_ln2.full <- lmer("cd_cosine_bert_ln2 ~ condition +
                                          dw_freq_zipf + (1 | item)",
                            data=e1.aff.rel,
                            REML = F)

summary(m.aff.rel.cd_cosine_bert_ln2.full)

a.aff.rel.cd_cosine_bert_ln2 <- anova(m.aff.rel.cd_cosine_bert_ln2.base, m.aff.rel.cd_cosine_bert_ln2.full)

a.aff.rel.cd_cosine_bert_ln2

```


### Afforded vs Non-Afforded

However we see no significant effect of afforded vs non-afforded

```{r}

# Comparison 1: Afforded to related
m.aff.naff.cd_cosine_bert_ln2.base <- lmer("cd_cosine_bert_ln2 ~ dw_freq_zipf + 
                                           (1 | item)",
                            data=e1.aff.naff,
                            REML = F)
m.aff.naff.cd_cosine_bert_ln2.full <- lmer("cd_cosine_bert_ln2 ~ condition +
                                           dw_freq_zipf + (1 | item)",
                            data=e1.aff.naff,
                            REML = F)

summary(m.aff.naff.cd_cosine_bert_ln2.full)

a.aff.naff.cd_cosine_bert_ln2 <- anova(m.aff.naff.cd_cosine_bert_ln2.base, m.aff.naff.cd_cosine_bert_ln2.full)

a.aff.naff.cd_cosine_bert_ln2

```


## Setting-Critical

The setting-critical embedding cosines show a larger gap for Afforded/Non-Afforded than for Afforded/Related

```{r}

e1 %>%
  ggplot(aes(x = condition, y = sc_cosine_bert_ln2, color=condition)) +
  geom_point(position=position_jitter(width=0.1), alpha=0.3) + 
  stat_summary(fun.data="mean_cl_boot", geom="point", size=3) + 
  stat_summary(fun.data="mean_cl_boot", geom="errorbar", width=0.2) + 
  geom_violin(alpha=0) +
  theme_minimal() + 
  theme(
    legend.position = "none"
  ) +
  scale_color_manual("Condition",
     values = c("#1eb809", "#2654d4", "#cc0502")) + 
  labs(
    y = "Setting-Continuation Cosine (BERT)",
    x = "Condition"
  )

```

### Related vs Afforded

There is no effect of related/afforded on sc_cosine.

```{r}

# Comparison 1: Afforded to related
m.aff.rel.sc_cosine_bert_ln2.base <- lmer("sc_cosine_bert_ln2 ~ 1 + dw_freq_zipf + 
                                          (1 | item)",
                            data=e1.aff.rel,
                            REML = F)
m.aff.rel.sc_cosine_bert_ln2.full <- lmer("sc_cosine_bert_ln2 ~ condition +
                                          dw_freq_zipf + (1 | item)",
                            data=e1.aff.rel,
                            REML = F)

summary(m.aff.rel.sc_cosine_bert_ln2.full)

a.aff.rel.sc_cosine_bert_ln2 <- anova(m.aff.rel.sc_cosine_bert_ln2.base, m.aff.rel.sc_cosine_bert_ln2.full)

a.aff.rel.sc_cosine_bert_ln2

```


### Afforded vs Non-Afforded

However the Afforded/Non-Afforded effect approaches significance.

```{r}

# Comparison 1: Afforded to related
m.aff.naff.sc_cosine_bert_ln2.base <- lmer("sc_cosine_bert_ln2 ~ dw_freq_zipf + 
                                           (1 | item)",
                            data=e1.aff.naff,
                            REML = F)
m.aff.naff.sc_cosine_bert_ln2.full <- lmer("sc_cosine_bert_ln2 ~ condition +
                                           dw_freq_zipf + (1 | item)",
                            data=e1.aff.naff,
                            REML = F)

summary(m.aff.naff.sc_cosine_bert_ln2.full)

a.aff.naff.sc_cosine_bert_ln2 <- anova(m.aff.naff.sc_cosine_bert_ln2.base, m.aff.naff.sc_cosine_bert_ln2.full)

a.aff.naff.sc_cosine_bert_ln2

```

# GPT-3

For GPT-3 I used the total surprisal of the setting and critical sentence together.

There is not much obvious variation in the visualisation, but this measure contains a lot of noise (surprisal of words before the distinguishing word) that should be dealt with by item intercepts.

```{r}

e1 %>%
  ggplot(aes(x = condition, y = gpt3_davinci_spl, color=condition)) +
  geom_point(position=position_jitter(width=0.1), alpha=0.3) + 
  stat_summary(fun.data="mean_cl_boot", geom="point", size=3) + 
  stat_summary(fun.data="mean_cl_boot", geom="errorbar", width=0.2) + 
  geom_violin(alpha=0) +
  theme_minimal() + 
  theme(
    legend.position = "none"
  ) +
  scale_color_manual("Condition",
     values = c("#1eb809", "#2654d4", "#cc0502")) + 
  labs(
    y = "Total Surprisal (GPT-3)",
    x = "Condition"
  )

```

## Related vs Afforded

GPT-3 shows no effect of Afforded vs Related on total surprisal.

```{r}

# Comparison 1: Afforded to related
m.aff.rel.gpt3_davinci_spl.base <- lmer("gpt3_davinci_spl ~ 1 + dw_freq_zipf + 
                                          (1 | item)",
                            data=e1.aff.rel,
                            REML = F)
m.aff.rel.gpt3_davinci_spl.full <- lmer("gpt3_davinci_spl ~ condition +
                                          dw_freq_zipf + (1 | item)",
                            data=e1.aff.rel,
                            REML = F)

summary(m.aff.rel.gpt3_davinci_spl.full)

a.aff.rel.gpt3_davinci_spl <- anova(m.aff.rel.gpt3_davinci_spl.base, m.aff.rel.gpt3_davinci_spl.full)

a.aff.rel.gpt3_davinci_spl

```

## Afforded vs Non-Afforded

However in contrast to the BERT-family results, we *do* see a difference of Afforded vs Non-Afforded.

```{r}

# Comparison 1: Afforded to related
m.aff.naff.gpt3_davinci_spl.base <- lmer("gpt3_davinci_spl ~ dw_freq_zipf + 
                                           (1 | item)",
                            data=e1.aff.naff,
                            REML = F)
m.aff.naff.gpt3_davinci_spl.full <- lmer("gpt3_davinci_spl ~ condition +
                                           dw_freq_zipf + (1 | item)",
                            data=e1.aff.naff,
                            REML = F)

summary(m.aff.naff.gpt3_davinci_spl.full)

a.aff.naff.gpt3_davinci_spl <- anova(m.aff.naff.gpt3_davinci_spl.base, m.aff.naff.gpt3_davinci_spl.full)

a.aff.naff.gpt3_davinci_spl

```


### Ada

Out of curiosity I re-ran the analysis with the test data from ADA (the worst GPT-3). Ada doesn't find an Aff/N-Aff difference. There are lots of models between Ada and Davinci so I don't know where performance would start to fall off.

```{r}

# Comparison 1: Afforded to related
m.aff.naff.gpt3_ada_spl.base <- lmer("gpt3_ada_spl ~ dw_freq_zipf + 
                                           (1 | item)",
                            data=e1.aff.naff,
                            REML = F)
m.aff.naff.gpt3_ada_spl.full <- lmer("gpt3_ada_spl ~ condition +
                                           dw_freq_zipf + (1 | item)",
                            data=e1.aff.naff,
                            REML = F)

summary(m.aff.naff.gpt3_ada_spl.full)

anova(m.aff.naff.gpt3_ada_spl.base, m.aff.naff.gpt3_ada_spl.full)

```


# Summary

```{r}

pvals.aff.naff <- c(a.aff.naff.bert$`Pr(>Chisq)`[2],
                    a.aff.naff.roberta$`Pr(>Chisq)`[2],
                    a.aff.naff.bert.nsp$`Pr(>Chisq)`[2],
                    a.aff.naff.cd_cosine_bert_ln2$`Pr(>Chisq)`[2],
                    a.aff.naff.sc_cosine_bert_ln2$`Pr(>Chisq)`[2],
                    a.aff.naff.gpt3_davinci_spl$`Pr(>Chisq)`[2])

pvals.aff.rel <- c(a.aff.rel.bert$`Pr(>Chisq)`[2],
                    a.aff.rel.roberta$`Pr(>Chisq)`[2],
                    a.aff.rel.bert.nsp$`Pr(>Chisq)`[2],
                    a.aff.rel.cd_cosine_bert_ln2$`Pr(>Chisq)`[2],
                    a.aff.rel.sc_cosine_bert_ln2$`Pr(>Chisq)`[2],
                    a.aff.rel.gpt3_davinci_spl$`Pr(>Chisq)`[2])

pvals.aff.rel <- round(pvals.aff.rel, 3)
pvals.aff.naff <- round(pvals.aff.naff, 3)

models <- c("BERT", "RoBERTa", "BERT", "BERT", "BERT", "GPT-3")

methods <- c("Masked LM", "Masked LM", "NSP", "C-D Cosine", "S-C Cosine", "Total surprisal")

summary <- data.frame(methods, models, pvals.aff.rel, pvals.aff.naff)
       
colnames(summary) <- c("Method", "Model", "Aff/Rel p-val", "Aff/N-Aff p-val")             

summary
```
